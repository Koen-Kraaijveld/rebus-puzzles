Running experiment... (model: llava-1.6-34b, prompt type: 4)
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|▋         | 1/15 [00:04<01:01,  4.37s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:08<00:54,  4.21s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:12<00:49,  4.14s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:16<00:46,  4.22s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [00:21<00:42,  4.22s/it]Loading checkpoint shards:  40%|████      | 6/15 [00:25<00:39,  4.40s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [00:30<00:35,  4.40s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [00:34<00:30,  4.31s/it]Loading checkpoint shards:  60%|██████    | 9/15 [00:38<00:25,  4.24s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [00:43<00:21,  4.40s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [00:47<00:17,  4.44s/it]Loading checkpoint shards:  80%|████████  | 12/15 [00:52<00:13,  4.52s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [00:57<00:09,  4.62s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [01:01<00:04,  4.47s/it]Loading checkpoint shards: 100%|██████████| 15/15 [01:02<00:00,  3.57s/it]Loading checkpoint shards: 100%|██████████| 15/15 [01:02<00:00,  4.19s/it]
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
{
   "experiment": "Llava-1.6-34b",
   "prompt_type": "4",
   "prompt_template": "<|im_start|>system\nAnswer the questions.<|im_end|><|im_start|>user\n<image>\nYou are given an image of a rebus puzzle. It consists of text or icons that is used to convey a word or phrase. It needs to be solved through creative thinking. You are also given a description of the graph representation of the puzzle. The nodes are elements that contain text or icons, which are then manipulated through the attributes of their node. The edges define spatial relationships between these elements. The description is as follows:\n{}\nWhich word/phrase is conveyed in this image and description from the following options (either A, B, C, or D)?\n(A) {} (B) {} (C) {} (D) {}\n<|im_end|><|im_start|>assistant\n",
   "n_puzzles": 682,
   "save_dir": "/var/scratch/hkd800/scripts/results/prompt_4",
   "models_dir": "/var/scratch/hkd800/scripts/models/downloads",
   "device": "cuda"
}
Prompting Llava-1.6-34b (phrases):   0%|          | 0/682 [00:00<?, ?it/s]Prompting Llava-1.6-34b (phrases):   0%|          | 0/682 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/var/scratch/hkd800/scripts/main.py", line 67, in <module>
    main()
  File "/var/scratch/hkd800/scripts/main.py", line 49, in main
    llava_experiment.run_on_benchmark(save_dir=save_dir)
  File "/var/scratch/hkd800/scripts/models/LlavaExperiment.py", line 79, in run_on_benchmark
    prompt = self.prompt.format(*prompt_format)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
IndexError: Replacement index 4 out of range for positional args tuple
