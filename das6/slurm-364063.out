Running experiment... (model: llava-1.6-34b, prompt type: 2)
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|▋         | 1/15 [00:04<01:03,  4.51s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:08<00:53,  4.11s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:11<00:46,  3.88s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:15<00:42,  3.89s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [00:19<00:39,  3.92s/it]Loading checkpoint shards:  40%|████      | 6/15 [00:23<00:35,  3.89s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [00:27<00:30,  3.84s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [00:30<00:26,  3.73s/it]Loading checkpoint shards:  60%|██████    | 9/15 [00:34<00:22,  3.67s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [00:38<00:18,  3.77s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [00:42<00:14,  3.71s/it]Loading checkpoint shards:  80%|████████  | 12/15 [00:45<00:11,  3.74s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [00:49<00:07,  3.87s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [00:53<00:03,  3.91s/it]Loading checkpoint shards: 100%|██████████| 15/15 [00:55<00:00,  3.13s/it]Loading checkpoint shards: 100%|██████████| 15/15 [00:55<00:00,  3.69s/it]
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
{
   "experiment": "Llava-1.6-34b",
   "prompt_type": 2,
   "prompt_template": "<|im_start|>system\nAnswer the questions.<|im_end|><|im_start|>user\n<image>\nYou are given a rebus puzzle. It consists of text or icons that is used to convey a word or phrase. It needs to be solved through creative thinking. Which word/phrase is conveyed in this image from the following options (either A, B, C, or D)?\n(A) {} (B) {} (C) {} (D) {}\n<|im_end|><|im_start|>assistant\n",
   "n_puzzles": 1008,
   "save_dir": "/var/scratch/hkd800/scripts/results/prompt_2",
   "models_dir": "/var/scratch/hkd800/scripts/models/downloads",
   "device": "cuda"
}
Prompting Llava-1.6-34b (phrases):   0%|          | 0/1008 [00:00<?, ?it/s]Prompting Llava-1.6-34b (phrases):   0%|          | 1/1008 [04:32<76:06:06, 272.06s/it]Prompting Llava-1.6-34b (phrases):   0%|          | 2/1008 [06:41<52:37:38, 188.33s/it]Prompting Llava-1.6-34b (phrases):   0%|          | 3/1008 [08:46<44:31:31, 159.49s/it]Prompting Llava-1.6-34b (phrases):   0%|          | 4/1008 [10:40<39:23:19, 141.23s/it]Prompting Llava-1.6-34b (phrases):   0%|          | 5/1008 [15:40<55:21:33, 198.70s/it]Prompting Llava-1.6-34b (phrases):   1%|          | 6/1008 [18:30<52:34:30, 188.89s/it]Prompting Llava-1.6-34b (phrases):   1%|          | 7/1008 [21:58<54:12:04, 194.93s/it]Prompting Llava-1.6-34b (phrases):   1%|          | 8/1008 [25:43<56:53:29, 204.81s/it]Prompting Llava-1.6-34b (phrases):   1%|          | 9/1008 [29:11<57:02:20, 205.55s/it]Prompting Llava-1.6-34b (phrases):   1%|          | 10/1008 [32:53<58:25:58, 210.78s/it]Prompting Llava-1.6-34b (phrases):   1%|          | 11/1008 [35:21<53:00:44, 191.42s/it]Prompting Llava-1.6-34b (phrases):   1%|          | 12/1008 [38:51<54:31:28, 197.08s/it]Prompting Llava-1.6-34b (phrases):   1%|▏         | 13/1008 [44:29<66:18:20, 239.90s/it]Prompting Llava-1.6-34b (phrases):   1%|▏         | 14/1008 [47:19<60:22:27, 218.66s/it]Prompting Llava-1.6-34b (phrases):   1%|▏         | 15/1008 [49:40<53:53:45, 195.39s/it]Prompting Llava-1.6-34b (phrases):   2%|▏         | 16/1008 [51:27<46:31:42, 168.85s/it]Prompting Llava-1.6-34b (phrases):   2%|▏         | 17/1008 [55:47<53:57:12, 196.00s/it]Prompting Llava-1.6-34b (phrases):   2%|▏         | 18/1008 [57:40<47:03:33, 171.12s/it]Prompting Llava-1.6-34b (phrases):   2%|▏         | 19/1008 [59:24<41:29:46, 151.05s/it]Prompting Llava-1.6-34b (phrases):   2%|▏         | 20/1008 [1:01:44<40:33:23, 147.78s/it]Prompting Llava-1.6-34b (phrases):   2%|▏         | 21/1008 [1:04:05<39:55:28, 145.62s/it]Prompting Llava-1.6-34b (phrases):   2%|▏         | 22/1008 [1:06:25<39:27:41, 144.08s/it]Prompting Llava-1.6-34b (phrases):   2%|▏         | 23/1008 [1:11:50<54:15:11, 198.29s/it]Prompting Llava-1.6-34b (phrases):   2%|▏         | 24/1008 [1:15:03<53:45:59, 196.71s/it]Prompting Llava-1.6-34b (phrases):   2%|▏         | 25/1008 [1:17:58<51:54:52, 190.12s/it]